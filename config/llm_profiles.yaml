# config/llm_profiles.yml
profiles:
  default:
    stages:
      planner:
        model: openai/gpt-5
        params:
          seed: 137
          json_mode: true

      draft:
        model: anthropic/claude-sonnet-4-5-20250929
        params:
          temperature: 0.2
          max_output_tokens: 12288

      fact:
        model: openai/gpt-5
        params:
          seed: 137
          json_mode: true

      revision:
        model: anthropic/claude-sonnet-4-5-20250929
        params:
          temperature: 0.2
          max_output_tokens: 12288
